---
layout: post
title: Please help me building a cloud visual SLAM system for cellphones
date: 2019-06-09 00:00:00 -0800
---

_Originally published on [Dev Community](https://dev.to/mjyc/please-help-me-building-a-cloud-visual-slam-system-for-cellphones-ine)_

Hello hackers, tinkers, webdevs, sysdevs, roboticists, and all coders! I've been excited about [cloud robotics](https://en.wikipedia.org/wiki/Cloud_robotics), a field of robotics that utilizes the power of cloud computing, and want to share the excitement with you and suggest a project we can potentially work together. The project that I'm thinking of is "cellphone visual SLAMing". The idea is to run a visual SLAM system on cloud so mobile devices like a cellphone can build 3D maps by simply uploading camera data to the cloud.

Here are the steps I'm thinking:

1. Try creating a 3D map using [ORB_SLAM2](https://github.com/raulmur/ORB_SLAM2) and desktop camera images.
   The main goal of this step is to get comfortable with a visual SLAM library and feel out the limitations.
2. Try creating 3D maps using ORB_SLAM2 running on a desktop and cellphone camera images.
   ORB_SLAM2 supports [ROS](https://www.ros.org/). So one can easily capture device camera images using [HTML5's `MediaDevices.getUserMedia()`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia), turn them into ROS image messages, and publish them using [roslibjs](https://github.com/RobotWebTools/roslibjs) so ORB_SLAM2 can use the images collected from a remote device.
3. Run the ORB_SLAM2 to cloud.
   I have not tried it, but it seems like it is fairly easy to [containerize a ROS package and deploy it on cloud](https://docs.docker.com/samples/library/ros/).

That's it! Are you interested in trying this idea out? If you have experiences with visual SLAM and have suggestions? [Let me know](https://dev.to/mjyc/please-help-me-building-a-cloud-visual-slam-system-for-cellphones-ine), I'd love to hear your thoughts.
